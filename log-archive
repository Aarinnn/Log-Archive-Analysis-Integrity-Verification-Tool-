#!/usr/bin/env python3

import datetime as dt
import shutil
import gzip
import brotli
import hashlib
from pathlib import Path


# Source log files to archive
log_files = [
    Path("/var/log/syslog"),
    Path("/var/log/auth.log"),
    Path("/var/log/kern.log"),
    Path("/var/log/apt/history.log"),
]

# Destination folder for archived logs
archive_folder = Path.home() / "log-archive"

# Make archive folder if not exists

archive_folder.mkdir(exist_ok=True)


# Timestamp for all logs)

timestamp = dt.datetime.now().strftime("%Y-%m-%d_%H-%M-%S")

# Loop through each source log file
for source_file in log_files:

    # Skip missing logs instead of crashing
    if not source_file.exists():
        print(f"[WARN] skipping missing file: {source_file}")
        continue

    stem = source_file.stem
    suffix = source_file.suffix
    new_name = f"{stem}_{timestamp}{suffix}"

    # Complete destination path
    dest = archive_folder / new_name

    # Copy the original log file to archive folder
    
    shutil.copy2(source_file, dest)

    # Compress the archived log into .gz
    
    compressed_path = str(dest) + ".gz"
    with open(dest, "rb") as f_in:
        with gzip.open(compressed_path, "wb") as f_out:
            shutil.copyfileobj(f_in, f_out)

    # Delete uncompressed copy
    dest.unlink()

    # Update dest to point at compressed file
    dest = Path(compressed_path)

    # Generate SHA-256 hash for integrity
    
    hash_path = str(dest) + ".sha256"   
    sha256 = hashlib.sha256()

    with open(dest, "rb") as f:
        for chunk in iter(lambda: f.read(4096), b""):
            sha256.update(chunk)

    digest = sha256.hexdigest()

    # Write "<hash> <filename>" into .sha256 file
    with open(hash_path, "w") as hash_file:
        hash_file.write(f"{digest}  {dest.name}\n")

    
    print(f"Archived to: {dest}")
    print(f"SHA-256: {digest}")

